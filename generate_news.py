import os
import time
import datetime
import feedparser
import google.generativeai as genai
import re
import random
from dataclasses import dataclass, field
from functools import lru_cache
from typing import Dict, List
from urllib.parse import urlparse

try:
    from googletrans import Translator
except ImportError:  # pragma: no cover - optional dependency for local dev
    Translator = None

@dataclass
class CategoryConfig:
    key: str
    display_name: str
    rss_feeds: List[str]
    archive_dir: str
    index_path: str
    max_articles: int = 15
    fallback_image_url: str = ""
    # selection_mode: ê¸°ì‚¬ ì„ íƒ ë°©ì‹ ì„¤ì • (ì›Œí¬í”Œë¡œ ì…ë ¥ â†’ í™˜ê²½ ë³€ìˆ˜ â†’ ê¸°ë³¸ê°’ ìˆœìœ¼ë¡œ ê²°ì •)
    #  - "time": RSSì—ì„œ ê°€ì ¸ì˜¨ ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬í•´ ìƒìœ„ Nê°œ ì„ íƒ
    #  - "random": ì •ë ¬ ì—†ì´ ë¬´ì‘ìœ„ ì„ê¸° í›„ ìƒìœ„ Nê°œ ì„ íƒ
    #  - "keyword": ì§€ì •í•œ í‚¤ì›Œë“œê°€ ì œëª©Â·ë³¸ë¬¸ì— ë“¤ì–´ê°„ ê¸°ì‚¬ë§Œ í•„í„°ë§ í›„ ìµœì‹  ìˆœìœ¼ë¡œ ì„ íƒ
    selection_mode: str = "time"
    keyword_filters: List[str] = field(default_factory=list)


# --- ì„¤ì • ---


def resolve_selection_mode(key: str, default: str = "time") -> str:
    # <ì¹´í…Œê³ ë¦¬>_SELECTION_MODE í™˜ê²½ ë³€ìˆ˜ë¡œ ì„ íƒ ëª¨ë“œë¥¼ ì§€ì •í•œë‹¤.
    # ì˜ˆ) AI ì¹´í…Œê³ ë¦¬ì— ëœë¤ ì ìš©: `export AI_SELECTION_MODE=random`
    # GitHub Actions( daily-news.yml )ì—ì„œ workflow_dispatch ì…ë ¥ì„ ì´ í™˜ê²½ ë³€ìˆ˜ë¡œ ì „ë‹¬í•œë‹¤.
    # ì§€ì› ê°’ ì™¸ê°€ ë“¤ì–´ì˜¤ë©´ ê¸°ë³¸ê°’(default)ì„ ì‚¬ìš©í•œë‹¤.
    env_val = os.getenv(f"{key.upper()}_SELECTION_MODE", default).strip().lower()
    if env_val in {"time", "random", "keyword"}:
        return env_val
    return default


def resolve_keyword_filters(key: str) -> List[str]:
    # <ì¹´í…Œê³ ë¦¬>_KEYWORDS í™˜ê²½ ë³€ìˆ˜ì— ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œë¥¼ ë„£ëŠ”ë‹¤.
    # ì˜ˆ) AI ì¹´í…Œê³ ë¦¬ì— "openai"ì™€ "llm"ì„ í•„í„°ë§: `export AI_KEYWORDS="openai,llm"`
    # daily-news.ymlì˜ workflow_dispatch ì…ë ¥ì´ ë™ì¼ ì´ë¦„ì˜ í™˜ê²½ ë³€ìˆ˜ë¡œ ì±„ì›Œì ¸ ì—¬ê¸°ì—ì„œ ì½íŒë‹¤.
    # í‚¤ì›Œë“œëŠ” ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì œëª©Â·ë³¸ë¬¸ì—ì„œ ê²€ìƒ‰ëœë‹¤.
    raw = os.getenv(f"{key.upper()}_KEYWORDS", "").strip()
    if not raw:
        return []
    return [kw.strip() for kw in raw.split(",") if kw.strip()]


# --- ì„¤ì • ---
CATEGORIES: Dict[str, CategoryConfig] = {
    "ai": CategoryConfig(
        key="ai",
        display_name="AI",
        rss_feeds=[
            "https://www.aitimes.com/rss/allArticle.xml",
            "https://www.bloter.net/archives/category/ai/feed",
            "https://www.reddit.com/r/ArtificialInteligence/top/.rss?t=day",
            "https://www.techmeme.com/feed.xml",
        ],
        archive_dir="docs/ai/daily",
        index_path="docs/ai/index.html",
        fallback_image_url="https://placehold.co/800x420/111827/FFFFFF?text=AI+News",
        selection_mode=resolve_selection_mode("ai"),
        keyword_filters=resolve_keyword_filters("ai"),
    ),
    "xr": CategoryConfig(
        key="xr",
        display_name="XR",
        rss_feeds=[
            "https://www.roadtovr.com/feed/",
            "https://uploadvr.com/rss",
            "https://arinsider.co/feed/",
            "https://skarredghost.com/feed/",
        ],
        archive_dir="docs/xr/daily",
        index_path="docs/xr/index.html",
        selection_mode=resolve_selection_mode("xr"),
        keyword_filters=resolve_keyword_filters("xr"),
    ),
}

# Gemini í˜¸ì¶œ ê°„ê²© (ë¬´ë£Œ í”Œëœì´ë©´ 6~7ì´ˆ ì´ìƒ ê¶Œì¥, ìœ ë£Œ/ì—¬ìœ  ìˆìœ¼ë©´ ì¤„ì—¬ë„ ë¨)
REQUEST_INTERVAL_SECONDS = 2
HIGHLIGHT_COLOR = "#fff6b0"


# **í…ìŠ¤íŠ¸** â†’ ê°•ì¡° ìƒ‰ìƒ(ë¬¸êµ¬ë§Œ) + ëª©ë¡ ì²˜ë¦¬
def markdown_bold_to_highlight(html_text: str) -> str:
    """Convert **bold** markers into highlighted phrases and list items."""

    def wrap_highlight(match):
        text = match.group(1)
        if len(text.split()) >= 2:
            return (
                f"<span class='highlight' style='background-color: {HIGHLIGHT_COLOR};"
                " padding: 3px 5px; border-radius: 4px;'>"
                f"{text}"
                "</span>"
            )
        return f"<strong>{text}</strong>"

    lines = []
    for raw_line in html_text.splitlines():
        cleaned = raw_line.strip()
        if not cleaned:
            continue
        cleaned = re.sub(r"^[â€¢â–¡\-]\s*", "", cleaned)
        converted = re.sub(r"\*\*(.+?)\*\*", wrap_highlight, cleaned)
        lines.append(converted)

    if not lines:
        return ""

    items = [f"<li>{line}</li>" for line in lines]
    return "<ul class='summary-list'>" + "".join(items) + "</ul>"


def contains_korean(text: str) -> bool:
    return bool(re.search(r"[ê°€-í£]", text))


_translator = None


@lru_cache(maxsize=256)
def translate_title_to_korean(title: str) -> str:
    """Translate English titles to Korean for display. Fallback to original on failure."""

    if not title or contains_korean(title):
        return title

    if Translator is None:
        return title

    global _translator
    if _translator is None:
        _translator = Translator()

    try:
        result = _translator.translate(title, dest="ko")
        if result and result.text:
            return result.text
    except Exception:
        pass

    return title


def format_timestamp(ts: float) -> str:
    if not ts:
        return "ë°œí–‰ ì‹œê° ì •ë³´ ì—†ìŒ"

    try:
        return datetime.datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M")
    except Exception:
        return "ë°œí–‰ ì‹œê° ì •ë³´ ì—†ìŒ"


def extract_source_name(entry, link: str) -> str:
    source_title = getattr(entry, "source", None)
    if source_title:
        title_val = getattr(source_title, "title", None)
        if title_val:
            return title_val

    netloc = urlparse(link or "").netloc
    if netloc.startswith("www."):
        netloc = netloc[4:]
    return netloc or "ì¶œì²˜ ë¯¸ìƒ"


def extract_image_url(entry) -> str:
    media_content = getattr(entry, "media_content", None) or []
    if media_content:
        first = media_content[0]
        if isinstance(first, dict) and first.get("url"):
            return first["url"]

    media_thumbnail = getattr(entry, "media_thumbnail", None) or []
    if media_thumbnail:
        thumb = media_thumbnail[0]
        if isinstance(thumb, dict) and thumb.get("url"):
            return thumb["url"]

    image_link = getattr(entry, "image", None)
    if isinstance(image_link, dict) and image_link.get("href"):
        return image_link["href"]

    def extract_from_html(html_text: str) -> str:
        if not html_text:
            return ""
        match = re.search(r"<img[^>]+src=['\"]([^'\"]+)['\"]", html_text, re.IGNORECASE)
        return match.group(1) if match else ""

    contents = getattr(entry, "content", None) or []
    for content in contents:
        if isinstance(content, dict):
            candidate = extract_from_html(content.get("value", ""))
        else:
            candidate = extract_from_html(getattr(content, "value", ""))
        if candidate:
            return candidate

    summary_html = getattr(entry, "summary", "") or getattr(entry, "description", "")
    html_candidate = extract_from_html(summary_html)
    if html_candidate:
        return html_candidate

    return ""


def sanitize_summary(summary: str) -> str:
    cleaned_lines = []
    for line in summary.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if "URL:" in stripped:
            continue
        if re.search(r"ì¶œì²˜\s*:", stripped):
            continue
        if re.search(r"https?://", stripped):
            continue
        cleaned_lines.append(stripped)

    return "\n".join(cleaned_lines)


# 1) Gemini ìš”ì•½ í•¨ìˆ˜
def summarize(text: str, title: str, display_name: str) -> str:
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])

    # ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ (í•„ìš”ì‹œ ë‹¤ë¥¸ IDë¡œ êµì²´)
    model = genai.GenerativeModel("gemini-2.5-flash-preview-09-2025")

    prompt = f"""
ì•„ë˜ {display_name} ê´€ë ¨ ê¸°ì‚¬ ë‚´ìš©ì„ 5ì¤„ ì´ë‚´ í•œêµ­ì–´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.
ê°€ëŠ¥í•˜ë©´ ìˆ˜ì¹˜, íšŒì‚¬ëª…, í•µì‹¬ ì´ìŠˆ ìœ„ì£¼ë¡œ í•˜ê³ , ê° ì¤„ì€ ë¶ˆë¦¿ ê¸°í˜¸ "â–¡"ìœ¼ë¡œ ì‹œì‘í•´ì¤˜.
í•µì‹¬ í‚¤ì›Œë“œëŠ” ê°•ì¡°(**êµµê²Œ**) ì²˜ë¦¬í•˜ë˜, URLì´ë‚˜ ë§í¬ëŠ” í¬í•¨í•˜ì§€ ë§ˆ.

ì œëª©: {title}
ë‚´ìš©:
{text[:2000]}
"""

    res = model.generate_content(prompt)
    return res.text.strip()


# 2) RSS â†’ (ì—¬ëŸ¬ RSS ì „ì²´) â†’ ì‹œê°„/ëœë¤ ì •ë ¬ â†’ ìƒìœ„ Nê°œë§Œ ìš”ì•½
def fetch_and_summarize(config: CategoryConfig):
    raw_items = []

    for feed_url in config.rss_feeds:
        d = feedparser.parse(feed_url)

        for entry in d.entries:
            title = getattr(entry, "title", "")
            link = getattr(entry, "link", "")
            content = getattr(entry, "summary", "") or getattr(
                entry, "description", ""
            )

            # ê²Œì‹œ ì‹œê°(published) ë˜ëŠ” ìˆ˜ì • ì‹œê°(updated) ì‚¬ìš©
            published = getattr(entry, "published_parsed", None) or getattr(
                entry, "updated_parsed", None
            )
            if published:
                ts = time.mktime(published)  # epoch time
            else:
                ts = 0  # ë‚ ì§œ ì •ë³´ ì—†ìœ¼ë©´ ê°€ì¥ ë’¤ë¡œ ë°€ë¦¼ (time ëª¨ë“œì¼ ë•Œ)

            raw_items.append((ts, title, link, content, entry))

    keywords = [kw.lower() for kw in config.keyword_filters]

    if config.selection_mode == "keyword" and keywords:
        # í‚¤ì›Œë“œ ëª¨ë“œ: ì œëª©+ë³¸ë¬¸ì— í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ëœ ê¸°ì‚¬ë§Œ ë‚¨ê¸´ë‹¤.
        # í‚¤ì›Œë“œëŠ” resolve_keyword_filters()ë¡œ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ì–´ì˜¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•œë‹¤.
        raw_items = [
            item
            for item in raw_items
            if any(kw in ((item[1] or "") + " " + (item[3] or "")).lower() for kw in keywords)
        ]

    # ê¸°ì‚¬ ì •ë ¬/ì„ íƒ ë°©ì‹
    three_days_ago = time.time() - 3 * 24 * 60 * 60
    if config.selection_mode == "time":
        # ì‹œê°„ ëª¨ë“œ: ê²Œì‹œ ì‹œê°(ts) ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ìµœì‹  ê¸°ì‚¬ë¶€í„° ì •ë ¬
        raw_items.sort(key=lambda x: x[0], reverse=True)
    elif config.selection_mode == "random":
        # ëœë¤ ëª¨ë“œ: ìµœê·¼ 3ì¼ ë‚´ ê¸°ì‚¬ë§Œ ëŒ€ìƒìœ¼ë¡œ ë¬´ì‘ìœ„ ì„ê¸° (ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©)
        recent_items = [item for item in raw_items if item[0] and item[0] >= three_days_ago]
        candidate_items = recent_items if recent_items else raw_items
        random.shuffle(candidate_items)
        raw_items = candidate_items
    elif config.selection_mode == "keyword":
        # í‚¤ì›Œë“œ ëª¨ë“œ: í•„í„°ë§ í›„ ìµœì‹  ìˆœ ì •ë ¬ (í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì•„ë˜ elseë¡œ ë™ì¼ ì²˜ë¦¬)
        raw_items.sort(key=lambda x: x[0], reverse=True)
    else:
        raw_items.sort(key=lambda x: x[0], reverse=True)

    # ìƒìœ„ Nê°œë§Œ ì„ íƒ
    selected = raw_items[: config.max_articles]

    summarized = []
    for idx, (ts, title, link, content, entry) in enumerate(selected):
        text_with_url = content + f"\n\nê¸°ì‚¬ URL: {link}"

        summary = summarize(text_with_url, title, config.display_name)
        summary = sanitize_summary(summary)
        image_url = extract_image_url(entry) or config.fallback_image_url

        summarized.append(
            {
                "title": title,
                "link": link,
                "summary": summary,
                "published_display": format_timestamp(ts),
                "source_name": extract_source_name(entry, link),
                "image_url": image_url,
            }
        )

        # ì¿¼í„° ë³´í˜¸ìš© ë”œë ˆì´
        time.sleep(REQUEST_INTERVAL_SECONDS)

    return summarized


# 3) ê°œë³„ ì‹¤í–‰(ë‚ ì§œ+ì‹œê°„) í˜ì´ì§€ ìƒì„±
def build_daily_page(articles, date_str: str, time_str: str, config: CategoryConfig) -> str:
    parts = []
    parts.append("<!DOCTYPE html>")
    parts.append("<html lang='ko'>")
    parts.append("<head>")
    parts.append("  <meta charset='utf-8' />")
    parts.append(f"  <title>{config.display_name} News - {date_str} {time_str}</title>")
    parts.append(
        "  <meta name='viewport' content='width=device-width, initial-scale=1' />"
    )
    parts.append("  <style>")
    parts.append(
        "    body { font-family: 'Noto Sans KR', 'Pretendard', sans-serif; line-height: 1.7; margin: 1.5rem; background: #f9fafb; color: #0f172a; }"
    )
    parts.append("    h1 { margin-bottom: 0.25rem; }")
    parts.append("    .meta { color: #475569; margin-bottom: 1.25rem; }")
    parts.append(
        "    .nav { display: flex; gap: 0.5rem; flex-wrap: wrap; margin-bottom: 1rem; }"
    )
    parts.append(
        "    .nav a { padding: 0.45rem 0.8rem; border: 1px solid #e5e7eb; border-radius: 8px; text-decoration: none; color: #0f172a; background: #fff; box-shadow: 0 1px 2px rgba(0,0,0,0.04); font-weight: 600; }"
    )
    parts.append("    .articles { display: grid; gap: 1rem; }")
    parts.append(
        "    .article-card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 1.1rem 1.2rem; box-shadow: 0 10px 25px rgba(15,23,42,0.06); }"
    )
    parts.append("    .article-card h2 { margin: 0; font-size: 1.15rem; }")
    parts.append(
        "    .article-card h2 a { color: #0f172a; text-decoration: none; }"
    )
    parts.append(
        "    .article-card h2 a:hover { text-decoration: underline; }"
    )
    parts.append(
        "    .original-title { display: block; font-size: 0.9rem; color: #6b7280; margin-top: 4px; }"
    )
    parts.append(
        "    .article-meta { color: #475569; font-size: 0.95rem; margin: 0.5rem 0 0.75rem; display: flex; gap: 0.5rem; align-items: center; flex-wrap: wrap; }"
    )
    parts.append(
        "    .meta-pill { background: #eef2ff; color: #4338ca; padding: 0.25rem 0.6rem; border-radius: 999px; font-weight: 600; font-size: 0.9rem; }"
    )
    parts.append(
        "    .article-body { display: flex; gap: 0.85rem; align-items: flex-start; flex-wrap: wrap; }"
    )
    parts.append(
        "    .summary-column { flex: 1 1 0; min-width: 0; }"
    )
    parts.append(
        "    .article-image { flex: 0 1 320px; width: clamp(170px, 30vw, 320px); height: auto; max-height: 320px; object-fit: cover; border-radius: 10px; border: 1px solid #e5e7eb; margin-left: 0; align-self: flex-start; }"
    )
    parts.append("    .summary-list { margin: 0; padding-left: 1.15rem; color: #0f172a; }")
    parts.append("    .summary-list li { margin-bottom: 0.35rem; }")
    parts.append(
        "    .highlight { background-color: %s; padding: 3px 5px; border-radius: 4px; }"
        % HIGHLIGHT_COLOR
    )
    parts.append("    @media (max-width: 768px) {")
    parts.append("      .article-body { flex-direction: column; gap: 0.75rem; }")
    parts.append(
        "      .article-image { order: 2; width: clamp(160px, 75%, 260px); max-width: 260px; max-height: 220px; flex: 0 0 auto; align-self: flex-start; }"
    )
    parts.append("      .summary-column { width: 100%; }")
    parts.append("    }")
    parts.append("  </style>")
    parts.append("</head>")
    parts.append("<body>")
    parts.append("  <div class='nav'>")
    parts.append("    <a href='../../index.html'>ğŸ  í™ˆìœ¼ë¡œ</a>")
    parts.append("    <a href='../index.html'>ğŸ“… ë‚ ì§œë³„ ëª©ë¡</a>")
    parts.append("  </div>")
    parts.append(f"  <h1>{date_str} {config.display_name} News</h1>")
    parts.append(f"  <p class='meta'>Updated at {time_str} (KST)</p>")
    parts.append("  <section class='articles'>")

    for art in articles:
        summary_html = markdown_bold_to_highlight(art["summary"])
        display_title = translate_title_to_korean(art["title"])
        original_hint = (
            f"<span class='original-title'>ì›ë¬¸ ì œëª©: {art['title']}</span>"
            if display_title != art["title"]
            else ""
        )

        parts.append("    <article class='article-card'>")
        parts.append(
            "      <h2>"
            f"<a href='{art['link']}' target='_blank'>{display_title}</a>"
            f"{original_hint}"
            "</h2>"
        )

        meta_bits = [bit for bit in [art.get("published_display"), art.get("source_name")] if bit]
        if meta_bits:
            extra_meta = " Â· ".join(meta_bits[1:]) if len(meta_bits) > 1 else ""
            extra_span = f"<span>{extra_meta}</span>" if extra_meta else ""
            parts.append(
                "      <p class='article-meta'>"
                f"<span class='meta-pill'>{meta_bits[0]}</span>"
                f"{extra_span}"
                "</p>"
            )

        if summary_html or art.get("image_url"):
            parts.append("      <div class='article-body'>")
            parts.append("        <div class='summary-column'>")
            if summary_html:
                parts.append(f"          {summary_html}")
            parts.append("        </div>")

            if art.get("image_url"):
                parts.append(
                    f"        <img src='{art['image_url']}' alt='ê¸°ì‚¬ ì´ë¯¸ì§€' class='article-image' loading='lazy'/>"
                )

            parts.append("      </div>")
        parts.append("    </article>")

    parts.append("  </section>")
    parts.append("</body>")
    parts.append("</html>")

    return "\n".join(parts)


# 4) index.html ëª©ë¡ í˜ì´ì§€ ì¬ìƒì„± (ì—¬ëŸ¬ ë²ˆ/í•˜ë£¨ ì—¬ëŸ¬ íšŒ ì‹¤í–‰ í¬í•¨)
def collect_run_entries(config: CategoryConfig):
    os.makedirs(config.archive_dir, exist_ok=True)

    files = [f for f in os.listdir(config.archive_dir) if f.endswith(".html")]

    run_entries = []
    for fname in files:
        base = fname.replace(".html", "")
        date_str = base
        time_str = ""

        if "_" in base:
            date_part, time_part = base.split("_", 1)
            date_str = date_part
            if len(time_part) >= 6:
                hh = time_part[0:2]
                mm = time_part[2:4]
                ss = time_part[4:6]
                time_str = f"{hh}:{mm}:{ss}"
            else:
                time_str = time_part
        run_entries.append((base, date_str, time_str, fname))

    run_entries.sort(key=lambda x: x[0], reverse=True)
    return run_entries


def rebuild_index_html(config: CategoryConfig):
    run_entries = collect_run_entries(config)

    parts = []
    parts.append("<!DOCTYPE html>")
    parts.append("<html lang='ko'>")
    parts.append("<head>")
    parts.append("  <meta charset='utf-8' />")
    parts.append(f"  <title>Daily {config.display_name} News Archive</title>")
    parts.append(
        "  <meta name='viewport' content='width=device-width, initial-scale=1' />"
    )
    parts.append("  <style>")
    parts.append(
        "    body { font-family: 'Noto Sans KR', 'Pretendard', sans-serif; margin: 1.25rem; line-height: 1.6; background: #f9fafb; color: #0f172a; }"
    )
    parts.append("    h1 { margin-bottom: 0.35rem; }")
    parts.append(
        "    .nav { display: flex; gap: 0.5rem; flex-wrap: wrap; margin-bottom: 1rem; }"
    )
    parts.append(
        "    .nav a { padding: 0.45rem 0.85rem; border: 1px solid #e5e7eb; border-radius: 8px; text-decoration: none; color: #0f172a; background: #fff; font-weight: 600; box-shadow: 0 1px 2px rgba(0,0,0,0.04); }"
    )
    parts.append(
        "    .run-list { list-style: none; padding: 0; display: grid; gap: 0.75rem; margin-top: 1rem; }"
    )
    parts.append(
        "    .run-item { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 0.9rem 1rem; box-shadow: 0 8px 18px rgba(15,23,42,0.05); }"
    )
    parts.append(
        "    .run-item a { color: #0f172a; text-decoration: none; font-weight: 700; }"
    )
    parts.append("    .run-item a:hover { text-decoration: underline; }")
    parts.append(
        "    .timestamp { color: #475569; font-size: 0.95rem; display: block; margin-top: 0.2rem; }"
    )
    parts.append("  </style>")
    parts.append("</head>")
    parts.append("<body>")
    parts.append("  <div class='nav'>")
    parts.append("    <a href='../index.html'>ğŸ  í™ˆìœ¼ë¡œ</a>")
    parts.append("  </div>")
    parts.append(f"  <h1>Daily {config.display_name} News Archive</h1>")
    parts.append(
        f"  <p>ì‹¤í–‰ ì‹œì (ë‚ ì§œ+ì‹œê°„, KST)ë³„ë¡œ ì €ì¥ëœ {config.display_name} ê¸°ì‚¬ ìš”ì•½ ëª©ë¡ì…ë‹ˆë‹¤.</p>"
    )

    if not run_entries:
        parts.append("  <p>ì•„ì§ ì €ì¥ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</p>")
    else:
        parts.append("  <ul class='run-list'>")
        for base, date_str, time_str, fname in run_entries:
            if time_str:
                label = f"{date_str} {time_str} {config.display_name} News"
            else:
                label = f"{date_str} {config.display_name} News"
            parts.append(
                "    <li class='run-item'>"
                f"<a href='daily/{fname}'>{label}</a>"
                f"<span class='timestamp'>ì›ë³¸ ìƒì„± ì‹œê°„: {date_str} {time_str or ''} (KST)</span>"
                "</li>"
            )
        parts.append("  </ul>")

    parts.append("</body>")
    parts.append("</html>")

    os.makedirs(os.path.dirname(config.index_path), exist_ok=True)
    with open(config.index_path, "w", encoding="utf-8") as f:
        f.write("\n".join(parts))


def build_root_index(categories: Dict[str, CategoryConfig]):
    categorized_runs = {cfg.key: collect_run_entries(cfg) for cfg in categories.values()}

    parts = []
    parts.append("<!DOCTYPE html>")
    parts.append("<html lang='ko'>")
    parts.append("<head>")
    parts.append("  <meta charset='utf-8' />")
    parts.append("  <title>AI & XR News Archives</title>")
    parts.append("  <meta name='viewport' content='width=device-width, initial-scale=1' />")
    parts.append("  <style>")
    parts.append(
        "    body { font-family: 'Noto Sans KR', 'Pretendard', sans-serif; margin: 1.25rem; line-height: 1.6; background: #f9fafb; color: #0f172a; }"
    )
    parts.append("    h1 { margin-bottom: 0.5rem; }")
    parts.append("    .subtitle { color: #4b5563; margin-bottom: 1rem; }")
    parts.append("    .tabs { display: flex; gap: 0.5rem; margin-bottom: 1rem; flex-wrap: wrap; }")
    parts.append(
        "    .tab-btn { padding: 0.45rem 0.9rem; border: 1px solid #d1d5db; border-radius: 8px; background: #f3f4f6; cursor: pointer; font-weight: 600; }")
    parts.append(
        "    .tab-btn.active { background: #111827; color: #f9fafb; border-color: #111827; }"
    )
    parts.append("    .tab-panel { display: none; }")
    parts.append("    .tab-panel.active { display: block; }")
    parts.append(
        "    .panel-card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 1rem 1.1rem; box-shadow: 0 8px 18px rgba(15,23,42,0.05); }"
    )
    parts.append("    ul { padding-left: 1.1rem; margin: 0; }")
    parts.append("    li + li { margin-top: 0.35rem; }")
    parts.append("    .timestamp { color: #6b7280; font-size: 0.95rem; margin-left: 0.35rem; }")
    parts.append("    .archive-link { margin: 0 0 0.5rem; font-weight: 700; }")
    parts.append("  </style>")
    parts.append("</head>")
    parts.append("<body>")
    parts.append("  <h1>AI & XR Daily News Archives</h1>")
    parts.append("  <p class='subtitle'>íƒ­ì„ ëˆŒëŸ¬ AI/XR ë‰´ìŠ¤ë¥¼ êµ¬ë¶„í•´ í™•ì¸í•˜ì„¸ìš”. ëª¨ë“  ì‹œê°ì€ í•œêµ­ í‘œì¤€ì‹œ(KST) ê¸°ì¤€ì´ë©°, ê³¼ê±° ì‹¤í–‰ ê²°ê³¼ë„ ëˆ„ì í•´ ë³´ì—¬ì¤ë‹ˆë‹¤.</p>")

    parts.append("  <div class='tabs'>")
    for cfg in categories.values():
        parts.append(
            f"    <button class='tab-btn' data-target='{cfg.key}'>{cfg.display_name} ë‰´ìŠ¤</button>"
        )
    parts.append("  </div>")

    for cfg in categories.values():
        runs = categorized_runs.get(cfg.key, [])
        parts.append(
            f"  <div class='tab-panel' id='{cfg.key}'>"
        )
        parts.append("    <div class='panel-card'>")
        parts.append(
            f"      <p class='archive-link'><a href='{cfg.key}/index.html'>{cfg.display_name} ì•„ì¹´ì´ë¸Œ ì „ì²´ ë³´ê¸° â†’</a></p>"
        )

        if not runs:
            parts.append("      <p>ì•„ì§ ì €ì¥ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</p>")
        else:
            parts.append("      <ul>")
            for base, date_str, time_str, fname in runs:
                label = f"{date_str} {time_str} KST" if time_str else f"{date_str} KST"
                parts.append(
                    "        <li>"
                    f"<a href='{cfg.key}/daily/{fname}'>{cfg.display_name} ë‰´ìŠ¤</a>"
                    f" <span class='timestamp'>{label}</span>"
                    "</li>"
                )
            parts.append("      </ul>")

        parts.append("    </div>")
        parts.append("  </div>")

    parts.append("  <script>")
    parts.append(
        "    const tabs = document.querySelectorAll('.tab-btn'); const panels = document.querySelectorAll('.tab-panel');"
    )
    parts.append(
        "    function activateTab(key) { panels.forEach(p => p.classList.toggle('active', p.id === key)); tabs.forEach(t => t.classList.toggle('active', t.dataset.target === key)); }"
    )
    parts.append(
        "    tabs.forEach(btn => btn.addEventListener('click', () => activateTab(btn.dataset.target)));"
    )
    parts.append("    if (tabs.length) { activateTab(tabs[0].dataset.target); }")
    parts.append("  </script>")
    parts.append("</body>")
    parts.append("</html>")

    os.makedirs("docs", exist_ok=True)
    with open("docs/index.html", "w", encoding="utf-8") as f:
        f.write("\n".join(parts))


# 5) main ì‹¤í–‰ í•¨ìˆ˜
def main():
    # GitHub ActionsëŠ” UTCì´ë¯€ë¡œ, UTC + 9ì‹œê°„ = KST
    now_utc = datetime.datetime.utcnow()
    now = now_utc + datetime.timedelta(hours=9)

    date_str = now.strftime("%Y-%m-%d")
    time_str = now.strftime("%H:%M:%S")

    # íŒŒì¼ ì´ë¦„ìš© ID (YYYY-MM-DD_HHMMSS, KST ê¸°ì¤€)
    run_id = now.strftime("%Y-%m-%d_%H%M%S")

    for cfg in CATEGORIES.values():
        articles = fetch_and_summarize(cfg)
        daily_html = build_daily_page(articles, date_str, time_str, cfg)

        os.makedirs(cfg.archive_dir, exist_ok=True)
        daily_path = os.path.join(cfg.archive_dir, f"{run_id}.html")

        # ë§¤ ì‹¤í–‰ë§ˆë‹¤ ìƒˆë¡œìš´ íŒŒì¼ ìƒì„±
        with open(daily_path, "w", encoding="utf-8") as f:
            f.write(daily_html)

        rebuild_index_html(cfg)

    build_root_index(CATEGORIES)


if __name__ == "__main__":
    main()
